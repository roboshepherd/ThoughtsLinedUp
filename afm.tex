\chapter{Validation of Attractive Field Model for Self-regulated MRTA}
\label{afm}
In this chapter,  AFM  has been explained as an interdisciplinary model of self-regulated DOL in social systems. The model has been developed under the EPSRC collaborative project ``Defying the rules â€“ how self-organizing systems work'' \cite{Arcaute+2008}. Here,  three different social systems: ants, humans and robots have been studied in order to identify generic mechanisms that lead sustainability of social systems through self-regulation.

The construction of AFM has been achieved through a series of collaborative interactions among the EPSRC project partners\footnote{The partners of this project were from University of West of England, University of Hull, University of Wales, Newport and Imperial College London and they researched on ants, humans, robots and mathematical models respectively.}. From the biological experiments of ants colonies {\em Temnothorax albipennis} the bottom-up rules have been inferred by examining the roles of feedback in collective performance of ants brood-sorting and nest construction after emigration to a new site. The observational data has been analysed from the self-organized infrastructural development of an {\em eco-village} by an open community of volunteers. These studies helped  to formalize the generic rules into a concrete model  and to validate this model by deploying it in robot controllers within the context of a manufacturing shop-floor scenario. In this chapter, the robotic validation of AFM has mainly been described with a brief presentation on interpretations of AFM from different social perspectives.
%%%%%%%%%%%%%%%%%%%%%
\section{Motivations}
\label{afm:motivations}
The idea of finding a generic model of DOL, by collaboratively  studying human, biological and artificial social systems, has many fascinating advantages. Below some of them have been presented.

Firstly, this interdisciplinary study makes it possible to develop a generic model of self-regulatory DOL by combining the strengths of different disciplines overcoming their individual shortcomings. For example, ant colonies are the ideal example for studying the self-regulatory social systems. However, it is very difficult to pin-point the exact mechanism leading to a specific behaviour. Artificial systems e.g.  multi-robot system can be used to explore and verify biological hypotheses using totally controlled experiments. Similarly, observational data from human social systems can be combined with the data from the biological experiments to enhance the understanding of self-regulatory mechanisms in both of these social systems.
 
Secondly, synergy of different methods, and experimental and observational data from disparate disciplines, give the ability to construct a more abstract and powerful model which may not be available through independent studies. The higher-level abstraction can be very helpful to find the usefulness of this model since one can easily differentiate between generic and domain-specific components of the model. Generic part guides  to design a core-framework that can be used to create basic characteristics of a system, whereas domain-specific part can be implemented independent of other disciplines. For example,different social systems use different communication mechanisms, yet almost all of them share many common aspects in their self-regulatory behaviours (Sec. \ref{bg:bio-comm}). 

Thirdly,  the scope of application of generic models has been extended in many folds by tackling the common challenges of different disciplines. For example, both human social organizations and multi-robot systems suffer from the scalability issue for large organization. The properties of local sensing and local communication with relatively incapable sensory organs/hardware are present in both ants and swarm robotic systems. Thus, the integration of solutions from three major disciplines gives  a highly flexible and extensible model of DOL.
%=====================================================================
\section{The Attractive Field Model}
\label{afm:model}
The author of this thesis greatly acknowledge the contribution of the EPSRC project collaborators to formalize and document AFM. The text of this section has been taken from the project documents and informal communications with project members except Sec. \ref{afm:so} and Sec. \ref{afm:mrs-interpretation} which are the author's own interpretations of AFM regarding self-regulation and robotic implementation.
%------------------------------
\subsection{Generic framework}
\label{afm:framework}
Inspired from the DOL in ants, humans and robots,  the following necessary and sufficient set of four requirements have been proposed for self-regulation in social systems.

\textbf{Requirement 1: Concurrence} The simultaneous presence of several options is necessary in order to meaningfully say that the system has organised into a recognisable structure.   In task-allocation terms the minimum requirement is a single task as well as the option of not performing any task.

\textbf{Requirement 2: Continuous flow of information} Self-organised social systems establish a flow of information over the period of time when self-organisation can be defined.  The task information provides the basis on which the agents self-organise by enabling them to perceive tasks and receive feedback on system performance.

\textbf{Requirement 3: Sensitization} The system must have a way of representing the structure produced by self-organisation, in terms of MRTA, which tasks the robots are allocated.  One of the simplest ways of representing this information is an individual preference parameter for each task-robot combination.  A system where each robot has different levels of preference or {\em sensitivity} to the available tasks, can be said to have to embody a distinct organisation through differentiation.

\textbf{Requirement 4: Forgetting} When a system self-organises by repeated increases in individual sensitisation levels, it is also necessary, in order to avoid saturation, to have a mechanism by which the sensitisation levels are reduced or {\em forgotten}.  In addition to avoiding the situation where a structure produced by self-organisation is eroded by an eventual increase of sensitisation values to a given maximum, forgetting also allows flexibility in the system, in that the structure can change as certain tasks become important and other tasks become less so.  This effect can be achieved by mechanisms such as a slow general decay of sensitisation values or explicit negative feedback.
%%
Building on the requirements for self-organised social systems, AFM formalises these requirements in terms of the relationships between properties of individual agents and of the system as a whole \cite{Arcaute+2008}.  AFM is a bipartite network, i.e. there are two different types of nodes.  One set of nodes describes the sources of the attractive fields, the tasks, and the other set describes the agents.  Edges only exist between different types of nodes and they encode the strength of the attractive field as perceived by the agent.  There are no edges between agent nodes.  Communication among entities is considered as part of the attractive fields.  There is also a permanent field representing the {\em no-task} option of not working in any of the available tasks. This option is modelled as a random walk. 
\begin{figure}[H]
\centering
\includegraphics[height=7cm, angle=0]{./dia-files/AFM-Diag3.eps}
%figure caption is below the figur
\caption{The attractive field model (AFM)}
\label{fig:afm} % Give a unique label
\end{figure}

The model is presented graphically in Fig. \ref{fig:afm}.  The elements depicted are:
\begin{enumerate}
\item Source nodes (o) are tasks to be allocated to agents
\item Agent nodes (x) e.g., ants, humans, or robots
\item Black solid edges represent the attractive fields and correspond to an agent's perceived stimuli from each task.
\item Green edges represent the attractive field of the ever present no-task option, represented as a particular task (w).
\item The black dashed lines are not edges, but represent how each agent is allocated to a single task at any point in time.
\end{enumerate}

The edges of the AFM network are weighted and the value of this weight describes the strength of the stimulus as perceived by the agent.  In a spatial representation of the model, the strength of the field depends on the physical distance of the agent to the source.  In information-based models, the distance can represent an agent's level of understanding of that task.  The strength of a field is increased through the sensitisation of the agent through experience with performing the task.  This elements is not depicted explicitly in Fig.~\ref{fig:afm} but is represented in the weights of the edges.  

In Fig.~\ref{fig:afm}, the nodes have arbitrary positions.  Even though the distance is physical in this case, it need not be.  When the model is applied to other domains, the distance can represent the accessibility of information or the time the information takes to reach the agent. 

In summary, from the above diagram of the network, one can see that each of the agents is connected to each of the tasks. This means that even if an agent is currently involved in a task, the probability that it stops doing it in order to pursue a different task, or to random walk, is always non-zero.
%%--------------------------------------------------------------------
\subsection{Relationship of AFM with self-organization}
\label{afm:so}
\begin{figure}[H]
\centering
\includegraphics[width=9cm, angle=0]
{./images/dia-files/self-org-2.eps}
%figure caption is below the figure
\caption{\small Four generic rules establish the self-regulated DOL in social systems}
\label{fig:afm-rules} % Give a unique label
\end{figure}

It is interesting to note that the proposed four generic rules can be considered as  the four major foundations of a self-organized system (Fig.  \ref{fig:afm-rules}). As discussed in Sec. \ref{bg:def:self-reg},  self-organized systems exhibit four distinct perspectives known as so-called ingredients or properties of self-organization. However, it is not clear how those properties can come into existence. Here, the four underlying mechanisms have been described that explains how self-organization can be realized in different social systems using the generic framework of self-regulation. This can be explained it in the following ways.

Firstly, multiple interactions become meaningful when {\em continuous flow of information} occurs  by exchanging signals or cues among agents or their environment  that regulates their behaviours. This, in turn, contribute to the task-allocation  and task-switching in the social level.  In swarm intelligence literature, multiple interactions are often described as an essential ingredient of self-organization. However, interactions without definite purposes may not contribute to the self-organization.\\
%%
Secondly, in swarm intelligence, positive feedback has been attributed as another mechanism of  self-organization. But it is not easy to understand what creates positive feedback in a social system. Possible answers might be the characteristic of the environment e.g. ants select shorter path since density of pheromones become higher and thus more ants becomes attracted to that path, the gradual decrease of response-threshold of individuals which increases the probability of selecting a task etc.  To make the answer more concrete, {\em sensitisation} or learning have explicitly been attributed as a mechanism of positive feedback. There might exist other mechanisms too. But clearly sensitisation will be one of the reliable mechanisms for achieving positive feedback.\\
%%
Thirdly, similar to positive feedback,  {\em forgetting} has been that contributes to provide negative feedback about a task or decreasing the probability to select it. Other negative feedback mechanisms can be implemented by assigning a saturation level to each task which is also present in AFM, for details see \citeasnoun{Arcaute+2008}.\\
%%
Finally, creating  artificial amplification of fluctuations or stochastic events is not a straight-forward issue. It throws  many open questions. Does a system designer intentionally impose irregularity in task-performance of agents?  Is random movement  enough for simulating randomness in a system?
Since emergencies do not always pop-up on request, the rule of {\em concurrency} enables agents to  maintain even a small amount of probability of selecting a low-priority, or less sensitized or distant task. This concurrency mechanism provides a high-degree of robustness in the system such that all tasks can be attended even if specialization of agents delays them in switching to some of the tasks.
%% 
 \subsection{Interpretation of AFM  in ant colonies}
 The interpretation of AFM in an ant colony almost exactly follows the above generic interpretation. For ants it is assumed that DOL is not genetically driven. Initially they are all equal. It is not fully understood how ants ``know'' or get information about tasks. But  they all interact directly and indirectly and perform tasks. The flow of information can take place in many different ways. As discussed in Sec. \ref{bg:bio-comm}, ants can get information through direct P2P, local or global broadcast and indirect pheromone communications. In any case, if an ant $i_{1}$ is closer to the source of information, i.e. task, than any other ant $i_{2}$, there will be larger probability that $i_{1}$ will get that information than $i_{2}$. If all ants are assumed to be initially equal it will be more likely that  $i_{1}$ will attend to that task. Thus each task can be  treated as an attractive source,  stimulating ants to go to it. Here the stimulus primarily depends on the distance.

In case of sensitization or learning, an ant that has performed a task, it is assumed that it will be more likely that it will be attracted to do it again. Here there is no encoding of individual performance, the specialists are more attracted towards the task but do not perform  the task quicker than other ants. Thus the performance of colony increases as a result of sensitisation. Simultaneity (concurrence) of tasks over period of time of self-regulation can also be achieved through spatial dependence of strength of stimulus. Some ants will be favoured to get information from multiple sources than others. When an ant does not do a task for relatively long time it is less probable that it will do that task again. This will lead to forgetting of their tasks gradually. Flexibility in task switching is achieved through this forgetting of tasks. A concrete interpretation of AFM in an ant colony, along with simulation results can be found in \citeasnoun{Arcaute+2008}.
%%
\subsection{Interpretation of AFM in  human societies}
The interpretation of AFM  in a human society can be made using many different approaches. For example, using Fig. \ref{fig:afm} the following can re-interpret the mappings of different nodes and characteristics of AFM for a human society.
\begin{itemize}
\item Source nodes (o) can be resources (or tasks).
\item Agents (x) can be people.
\item The links can correspond to the flow of information about resources (or tasks) among people.
\item The distance dependence can be introduced here in the same way as with the ants. People working in a certain area are more likely to receive information of resources with respect to that area, than another person doing something else. How a person uses that information, corresponds to that person's ability to contribute towards a given goal.The weight of the link is the amount of information a person can get. The person can use it or dismiss it. Random walking would correspond to dismiss it. AFM does not differentiate between good and bad information. It is always considered as good information. 
\end{itemize}
Similar to the above biological interpretation, one can find that in human society the DOL can also be interpreted in terms of AFM. People can get information about certain tasks or resources from various sources. Those who are located near the source of information are more likely to attend it, e.g. through the access to Internet, some people can get information quicker than others. This can be treated as the distance to tasks or resources. The motivation of a person to use information can also be treated as the distance in the model. The background training, education or skill profile can be used to estimate the sensitization to do a task or use a resource. The urgency of a task can be inferred through some other estimates, e.g. the frequency of mentioning about a task, by team members or peers.
%%------------------------------------------------------------------
\subsection{Interpretation of AFM in multi-robot systems}
\label{afm:mrs-interpretation}
The interpretation of AFM in a multi-robot system also follows almost exactly as in generic interpretation. However, in order to make the interpretation more concrete, let be a manufacturing shop floor scenario, where $N$ number of autonomous mobile robots are required to attend $J$ number of shop tasks spread over a fixed area $A$. Let these tasks be represented by a set of small rectangular boxes resembling to manufacturing machines.

%%
Let $R$ be the set of robots ${r_1, r_2,...,r_n}$. Let a task $j$ has an associated task-urgency $\phi_j$ indicating its relative importance over time.
If a robot attends a task $j$ in the $x^{th}$ time-step, the value of $\phi_j$ will decrease by an amount $\delta_{\phi_{DEC}}$ in the $(x+1)^{th}$ time-step.
On the other hand, if a task has not been served by any robot in the $x^{th}$ time-step, $\phi_j$ will increase by another amount  $\delta_{\phi_{INC}}$  in $(x+1)^{th}$ time-step. Thus
%-- Phi update
urgency of a task is updated by the following rules.
\begin{equation}
 If\hspace*{0.15cm}the\hspace*{0.15cm} task\hspace*{0.15cm}is\hspace*{0.15cm}not\hspace*{0.15cm}being\hspace*{0.15cm} done:\hspace*{0.15cm}  \phi_j \rightarrow   \phi_j \hspace*{0.15cm} + \delta_{\phi_{INC}}
\label{eqn:delta-phi1}
\end{equation}
%%
\begin{equation}
 If\hspace*{0.15cm}the \hspace*{0.15cm}task\hspace*{0.15cm}is\hspace*{0.15cm}being\hspace*{0.15cm}done:\hspace*{0.15cm}  \phi_j \rightarrow   \phi_j \hspace*{0.15cm} - n\hspace*{0.10cm}\delta_{\phi_{DEC}}
\label{eqn:delta-phi2}
\end{equation}
Eq. \ref{eqn:delta-phi1} refers to a case where no robot attend to task $j$ and Eq. \ref{eqn:delta-phi2} refers to another case where $n$ robots are concurrently performing the task $j$.

In order to complete a task $j$, a robot $r_i$ needs to be within a fixed boundary $D_{j}$. If a robot completes a task $j$ it learns about it and this will influence $r_i$'s likelihood of selecting that task in future, say through increasing  its sensitization to $j$ by a small amount, $k_{INC}$. Here, the variable affinity of a robot $r_i$ to task $j$ is called as its {\em sensitization} $k^{i}_{j}$. If a robot $i$ does not do a task $j$ for some time, it forgets about $j$ and $k^i_j$ is decreased, by another small amount, say $k_{DEC}$ .
Thus a robot's task-sensitization update follows these rules.
\begin{equation}
 If\hspace*{0.15cm}task\hspace*{0.15cm}is\hspace*{0.15cm}done:\hspace*{0.15cm}  k^i_j \rightarrow   k^i_j \hspace*{0.15cm} + \hspace*{0.15cm} k_{INC}
\label{eqn:k-inc}
\end{equation}
\begin{equation}
 If\hspace*{0.15cm}task\hspace*{0.15cm}is\hspace*{0.15cm}not\hspace*{0.15cm}done:\hspace*{0.15cm}  k^i_j \rightarrow   k^i_j \hspace*{0.15cm} - \hspace*{0.15cm} k_{DEC}
\label{eqn:k-dec}
\end{equation}

According to AFM, all robots will establish attractive fields to all tasks due to the presence of a system-wide continuous flow of information. The strength of these attractive fields will vary according to the dynamic distances between robots and tasks, task-urgencies and corresponding sensitizations of robots. Simplifying the generic implementation of AFM from \citeasnoun{Arcaute+2008},  this stimuli of attractive field can formally be encoded as follows.
%% S
\begin{equation}
S_{j}^{i} = tanh\{\frac{k_{j}^{i}}{d_{ij}+\delta } \phi _{j}\}
\label{eqn:afm1}
\end{equation}
%--P(Task)
\begin{equation}
S^{i}_{RW} = tanh \left \{ 1 -  \frac{ \sum_{j=1}^{J} S^{i}_{j}}{J + 1} \right \}
\label{eqn:afm2}
\end{equation}
%-- P(RW)
\begin{equation}
P_{j}^{i} = \frac{S_{j}^{i}}{\sum_{j=0}^{J} S_{j}^{i}} \hspace*{0.25cm}where,\hspace*{0.25cm}S^{i}_{0} = S^{i}_{RW}   
\label{eqn:afm3}
\end{equation}

Eq. \ref{eqn:afm1} states that the stimuli of a robot $r_i$ to a particular task $j$, $S^{i}_{j}$ depends on $r_i$'s spatial distance to $j$ ($d_{ij}$), level of sensitization to $j$ ($k_{j}^{i}$), and perceived urgency of that task ($\phi _{j}$). In  Eq. \ref{eqn:afm1},  a very small constant value $\delta$ is used to avoid division by zero, in the case when a robot has reached to a task. Since $S^{i}_{j}$ is a probability function, it is chosen as a $tanh$ in order to keep the values between 0 and 1. Eq. \ref{eqn:afm2} suggests how  one can estimate the stimuli of random walk or no-task option. This stimuli of random walk depends on the sum of stimulus of $J$ real tasks. Here, random-walk is also considered as a task. Thus the total number of tasks become $J+1$. The probability of selecting each task has been determined by a probabilistic method outlined in Eq. \ref{eqn:afm3} which states that the probability of choosing a task $j$ by robot $r_i$ is directly proportional to its calculated stimuli $ S^i_j$. Finally, let $T_a$ be the allocated time to accomplish a task. If a robot can enter inside the task boundary within $T_a$ time it waits there until $T_a$ elapsed. Otherwise it will select a different task.
%%
%%=================================================================
\section{A manufacturing shop-floor scenario}
\label{afm:vms}
By extending the interpretation of AFM in multi-robot system, one can set-up manufacturing shop-floor  scenario. Here, each task represents a manufacturing machine that is  capable of producing goods from raw materials, but they also require constant maintenance works for stable operations. Let $W_{j}$ be a finite number of material parts that can be loaded into a machine $j$ in the beginning of its production process and in each time-step, $\omega_{j}$ units of material parts can be processed  ($\omega_{j} \ll W_{j} $). So let $\Omega_{j}^{p}$ be the initial production workload of $j$ which is simply: $W_{j} / \omega_{j}$ unit.

It is assumed that all machines are identical. In each time step, each machine always requires a minimum threshold number of robots, called hereafter as {\em minimum robots per machine ($\mu$)}, to meet its constant maintenance work-load, $\Omega_{j}^{m}$ unit. However, if $\mu$ or more robots are present in a machine for production purpose, it is assumed that, no extra robot is required to do its maintenance work separately. These robots, along with their production jobs, can do necessary maintenance works concurrently. For the sake of simplicity, the value of $\mu$ can be assumed as 1.

Now the above production and maintenance work-loads and task performance of robots need to converted into a unit task-urgency scale. The manufacturing operation can be divided into two subsequent stages: 1) \acfi{PMM}, and 2) \acfi{MOM}. Initially a machine starts working in PMM and does production and maintenance works concurrently. When there is no production work left, then it  enters into MOM. 
%%
\begin{figure}[H]
\centering
\includegraphics[width=12cm, angle=0]
{./images/VSP.eps}
%figure caption is below the figure
\caption{A manufacturing shop-floor production and maintenance cycle}
\label{fig:vsp}  % Give a unique label
\end{figure}

Fig. \ref{fig:vsp} illustrates this scenario for a single machine. Under both modes, let $\alpha_{j}$ be the amount of workload occurs in a unit time-step if no robot serves a task and it corresponds to a fixed task-urgency $\Delta \phi_{INC}$. On the other hand, it is assumed that in each time-step, a robot, $i$, can decrease a constant workload $\beta_{i}$ by doing some maintenance work along with doing any available production work. This  corresponds to a negative task urgency: $- \Delta \phi_{DEC}$. So, at the beginning of production process, task-urgency, occurred in a machine due to its production work-loads, can be encoded by Eq. \ref{eqn:task-urgency-prod-init}.
\begin{equation}
%\small
\Phi_{j, INIT}^{PMM} = \Omega_{j}^{p} \times \Delta \phi_{INC} + \phi_{j}^{m0}
\label{eqn:task-urgency-prod-init}
\end{equation}
where $\phi_{j}^{m0}$ represents the task-urgency due to any initial maintenance work-load of $j$.
Now if no robot attends to serve a machine, each time-step a constant maintenance workload of $\alpha_{j}^{m}$ will be added to $j$ and that will increase its task-urgency by $\Delta \phi_{INC}$. So, if $k$ time steps passes without any production work being done, task urgency at $k^{th}$ time-step will follow Eq. \ref{eqn:task-urgency-prod-case1}.
\begin{equation}
\Phi_{j, k}^{PMM} =\Phi_{j, INIT}^{PMM} + k \times \Delta \phi_{INC}
\label{eqn:task-urgency-prod-case1}
\end{equation}
However, if a robot attends to a machine and does some production works from it, there would be no extra maintenance work as it is assumed that $\mu$ = 1. Rather, the task-urgency on this machine will decrease by $\Delta \phi_{DEC}$ amount. If $\nu_{k}$ robots work on a machine simultaneously at time-step $k$, this decrease will be: $\nu_{k} \times \Delta \phi_{DEC}$. So in such cases, task-urgency in $(k+1)^{th}$ time-step can be represented by:
\begin{equation}
\Phi_{j, k+1}^{PMM} = \Phi_{j, k}^{PMM} - \nu_{k} \times \Delta \phi_{DEC}
\label{eqn:task-urgency-prod-case2}
\end{equation}
At a particular machine $j$, once $\Phi_{j, k}^{PMM}$ reaches to zero, it can be said that there is no more production work left and this time-step $k$ can give the {\em production completion time} of $j$, $T_{j}^{PMM}$. Average production time-steps of a shop-floor with M machines can be calculated by the following simple equation.
\begin{equation}
T_{avg}^{PMM} = \frac{1}{M} \sum_{j=1}^{M} T_{j}^{PMM} 
\label{eqn:avg-pmm}
\end{equation}
$T_{avg}^{PMM}$ can be compared with the minimum number of time-steps necessary to finish production works, $T_{min}^{PMM}$. This can only happen in an ideal case where all robots work for production without any random walking or failure. One can get $T_{min}^{PMM}$ from the total amount of work load and maximum possible inputs from all robots. If there are M machines and N robots, each machine has $\Phi_{INIT}^{PMM}$ task-urgency, and each time-step robots can decrease N $\times$ $\Delta \phi_{DEC}$ task-urgencies, then the theoretical $T_{min}^{PMM}$ can be found from the following Eq. \ref{eqn:min-pmm}.
%
%\begin{multicols}{2}
%\small
\begin{equation}
T_{min}^{PMM} = \frac{M \times \Phi_{INIT}^{PMM}}{N \times \Delta \phi_{DEC}} 
\label{eqn:min-pmm}
\end{equation}
%\vspace*{0.2cm}
\begin{equation}
\zeta_{avg}^{PMM} = \frac{T_{avg}^{PMM} - T_{min}^{PMM}}{T_{min}^{PMM}} 
\label{eqn:appd}
\end{equation}
%\end{multicols}
Thus one can define $\zeta_{avg}^{PMM}$, \acf{APCD} by following Eq. \ref{eqn:appd},
%%
When a machine enters into MOM, only $\mu$ robots are required to do its maintenance works in each time step. So, in such cases, if no robot serves a machine, the growth of task-urgency will follow Eq. \ref{eqn:task-urgency-prod-case1}. However, if $\nu_{k}$ robots are serving this machine at a particular time-step $k^{th}$ , task-urgency at $(k+1)^{th}$ time-step can be represented by:
\begin{equation}
\Phi_{j, k+1}^{MOM} = \Phi_{j, k}^{MOM}- (\nu_{k} - \mu) \times \Delta \phi_{DEC}
\label{eqn:task-urgency-maint-case}
\end{equation}
By considering $\mu = 1$, Eq. \ref{eqn:task-urgency-maint-case} will reduces to Eq. \ref{eqn:task-urgency-prod-case2}. Here, $\Phi_{j, k+1}^{MOM}$ will correspond to the {\em pending maintenance work-load} of a particular machine at a given time. This happens due to the random task switching of robots with a no-task option (random-walking). Interestingly PMW will indicate the robustness of this system since higher PMW value will indicate the delay in attending maintenance works by robots. One can find the \acfi{APMW} per time-step per machine, $\chi_{j}^{MOM}$ (Eq. \ref{eqn:sigle-pmw}) and average PMW per machine per time-step, $\chi_{avg}^{MOM}$ (Eq. \ref{eqn:avg-pmw}).
%\begin{multicols}{2}
%\small
\begin{equation}
\chi_{j}^{MOM}= \frac{1}{K} \sum_{k=1}^{K} \Phi_{j, k}^{MOM}
\label{eqn:sigle-pmw}
\end{equation}
%\vspace*{0.2cm}
\begin{equation}
\chi_{avg}^{MOM}= \frac{1}{M} \sum_{j=1}^{M} {\chi_{j}^{MOM}}
\label{eqn:avg-pmw}
\end{equation}
%\end{multicols}
%%%%%%==================================================================
\section{Experiment design}
\label{afm:expt-design}
A set of  manufacturing shop-floor scenario experiments have been designed for validating the effectiveness of AFM in producing self-regulated MRTA.  The overall aim of this design is to analyse the various properties of task-allocation and related other issues. In this section,  the design of the observables and parameters of the experiments have been described within the context of a manufacturing shop-floor scenario. 
%----------------------------------------------------------
\subsection{Observables}
\textbf{Plasticity:} As discussed in Sec. \ref{bg:def:dol},  self-regulated DOL can be characterised by plasticity and task-specialization, in both macroscopic and microscopic levels. Within manufacturing shop-floor context, plasticity refers to the collective ability of the robots to switch from doing no-task option (random-walking) to doing a task (or vice-versa) depending on the work-load present in the system. Here one can expect to see that most of the robots would be able to engage in tasks when there would be high workloads (or task-urgencies) during PMM. Similarly, when there would be low workload in case of MOM only a few robots would do the task, rest of them would either be idle (not doing any task) or perform a random-walk.  The changes of task-urgencies and the ratio of robots engaged in tasks can be good metrics to observe plasticity in MRTA.\\
%%
\textbf{Task-specialization:} Under heavy work-load most of the robots should attend to tasks. But self-regulated DOL is always accompanied with task-specializations of agents. That means that few robots will be more active than others. From AFM, one can see that after doing a task a few times, a robot will soon be sensitized to it. Therefore, from the raw log of task-sensitization of robots, one can be able to find the pattern of task-sensitization of robots per task basis. If a few robots specialize on a particular task that will help to reduce traffic near the task and improves overall efficiency of the system. Thus, at the end of the production cycle in manufacturing shop-floor scenario, one can count the percentage of robots specializes on each task in the experiments.\\
%%
\textbf{Quality of task-performance:} As discussed in Sec. \ref{afm:vms} one can measure the quality of MRTA from the APCD. It first calculates the ideal minimum production time and then finds the delay in production process from the actual production completion data. Thus this will indicate how much more time is  spent in the production process due to the self-regulation of robots in this distributed task-allocation scheme.  In order to calculate APCD, one can find the production completion time for each task from the raw log of task-urgency and make an average from them.\\
%%
\textbf{Robustness:} In order to see if  the system can respond to the gradually increasing workloads,  one can measure APMW within the context of the manufacturing shop-floor scenario. This can show the robustness of a system where a task can be  unattended for long time. When a task is not being served by any robot for some time, one can see that its urgency will rise and robots will respond to this dynamic demand. For measuring APMW  only the task-urgency data is needed.\\
%%
\textbf{Flexibility:} From the design of AFM, it is known that robots that are not doing a task will be de-sensitized to it or forget that task. So at an overall low work-load (or task urgency), less robots will do the tasks and hence less robots will have the opportunity to learn tasks. From the shop-floor work-load data, it can be confirmed the presence of flexibility in MRTA.\\
%%
\textbf{Energy-efficiency:} In order to characterize the energy-efficiency in MRTA  the pose data of each robot can be logged that can give the total translations occurred by all robots in MRTA experiments. This can give a rough indication of energy-usage by the robots. \\
%%
\textbf{Information flow:} Since AFM requires a system-wide continuous flow of information, one can measure the communication load to bench-mark the implementation of communication system. This bench-mark data can be used to compare among various communication strategies. Here one can measure  how much task-related information, i.e. task-urgency, location etc. are sent to the robots at each time step. This  amount of information or communication load can be constant or variable depending on the design of the communication system.\\
%%
\textbf{Scalability:} In order to see the effects of scaling on MRTA, two series of experiments have been designed. {\em Series A} corresponds to a small group where  8 robots are used for 2 tasks under an arena of 2 $m^2$. The numbers have been doubled in {Series B}, i.e. 16 robots, 4 tasks under an arena of 4 $m^2$. This proportional design can give a valuable insight about the effects of scaling on self-regulated MRTA. All of the above metrics of Set A and Set B can be compared to find those scalability effects.

Thus, in order to observe the above properties of self-regulated MRTA, the following  observables have been recorded in each time-step.
\begin{enumerate}
\item Task-urgency of each task ($\phi$).
\item Number of robots engaged in each task.
\item Task-sensitizations ($k$) of robots.
\item Pose data of robots.
\item Communication of task-information message with robots.  
\end{enumerate}
%%
\begin{table}
\caption{Experimental parameters of Series A \& B experiments}
\label{table:params}
\begin{center}
\begin{tabular}{|l|c|}
\hline Parameter & Series A $\mid$ Series B\\
\hline Total number of robots ($N$) & \hspace*{0.1cm} 8 $\mid$ 16\\
\hline Total number of tasks ($M$) & 2 $\mid$ 4\\
\hline Experiment area ($A$) & 2 $m^2$ $\mid$  4 $m^2$\\
\hline Initial production work-load/machine ($\Omega_{j}^{p}$) & 100 unit \\
\hline Task urgency increase rate ($\Delta\phi_{INC}$) & 0.005\\
\hline Task urgency decrease rate ($\Delta\phi_{DEC}$) & 0.0025\\
\hline Initial sensitization ($K_{INIT}$) & 0.1\\
\hline Sensitization increase rate ($\Delta k_{INC}$) & 0.03\\
\hline Sensitization decrease rate ($\Delta k_{DEC}$) & 0.01\\
\hline
\end{tabular}
\end{center}
\end{table}
%-------------------------------------------------------------------- 
\subsection{Parameters}
Table \ref{table:params} lists a set of essential parameters of the experiments. A relatively complex environment has been set-up, i.e., a high number of robots and tasks in a large area. The diameter of the marker of e-puck robot is 0.08m. So, if 4 robots are put in an area of one square meter, this will give a robot-occupied-space to free-space ratio of about 1:49 per square meter. This ratio is reasonable in order to allow the robots to move at a speed of 5 cm/sec without much interference to each other. 

The initial values of task urgencies correspond to 100 units of production work-load without any maintenance work-load as outlined in Eq. \ref{eqn:task-urgency-prod-init}.  A limit of 0 and 1 is chosen, where 0 means no urgency and 1 means maximum urgency. Same rule applies to sensitisation, where 0 means no sensitisation and 1 means maximum sensitisation. This also implies that if sensitization is 0, task has been forgotten completely. On the other hand, if sensitization is 1, the task has been learnt completely.  A default sensitization value of 0.1 has been selected for all tasks. The following relationships are maintained for selecting task-urgency and sensitization parameters.
\begin{equation}
\Delta\phi_{INC} = \frac{\Delta\phi_{DEC} \times N}{2 \times M}
\label{eqn:task-urgency}
\end{equation}
%
\begin{equation}
\Delta k_{DEC} = \frac{\Delta k_{INC}} {M - 1} 
\label{eqn:sensitization}
\end{equation}
%
Eq. \ref{eqn:task-urgency} establishes the fact that task urgency will increase at a higher rate than that of its decrease. In order to keep a task left unattended for a long time  a higher rate of increase of task urgency has been chosen. This difference is set on the basis of the assumption that at least half of the expected number of robots (ratio of number of robots to tasks) would be available to work on a task. So they would produce similar types of increase and decrease behaviours in task urgencies.

Eq. \ref{eqn:sensitization} suggests that the learning will happen much faster than the forgetting. The difference in these two rates is based on the fact that faster learning gives a robot more chances to select a task in next time-step and thus it becomes more specialized on it. %Task-Server updates task-info messages in the interval of $\Delta TS_u$=5s and robots stick on to a particular task for a maximum of $\Delta RT_{to}$=10s.
%%======================================================================
\section{Implementation}
\label{afm:impl}
%%
Ideally, AFM can be implemented as a complete distributed task-allocation system where each agent selects its own task based on its own external perception about task-urgencies (i.e. attractive fields),  distances from tasks and internal task-sensitisation records. Such an implementation requires powerful robots with sophisticated sensors (camera, laser etc.) and sufficient computation and communication  capabilities. In that case, robots can keep  task-urgency information up-to-date  through suitable local communication  schemes with their peers who can monitor the tasks. By using suitable navigation and mapping modules, they can also accurately calculate the distances from tasks and navigate to tasks autonomously. Moreover, they also require necessary hardware to do the actual task, e.g. gripper for pick-up tasks.

However, in this study has been undertaken to find the suitable communication schemes that can effectively spread the attractive fields (task-urgencies) among robots. So the complexities of a full-fledged implementation have been simplified by using a centralized communication system  that effectively makes up the limitations of e-puck robots.  For example, these robots are not  capable of sensing a task to estimate its urgencies, instead a centralized {\em task-perception server (TPS)} broadcast task information, e.g. task-urgencies, locations etc. to robots in certain time intervals. Within this interval, if some robots work on a task, they independently send their status, i.e. which task they are currently doing. From this status message,  TPS can re-calculate the task-urgencies and send them in next broadcast. 
%%
\begin{figure}[H]
\centering
\includegraphics[height=7cm, angle=0]{./images/CentralizedComm.eps}
\caption{\small A centralized communication scheme} % for implementing AFM}
\label{fig:ccm} % Give a unique label
\end{figure}

Fig. \ref{fig:ccm} shows how three robots are attracted to two different tasks and their communications with TPS. Here although the robots are selecting task independently based-on the strength of their attractive fields to different tasks, they are depended on the TPS for task-information.

This centralized communication system can be converted into a decentralized one where robots can use local observation and communication with peers about tasks to estimate task-urgencies. In Chapter \ref{local-comm}, an emulation of this scenario is presented where robots do not depend entirely on TPS for estimating task-urgencies, instead they get task information from TPS when they are very close to a task (inside a pre-defined task-boundary) or from local peers who know about a task via TPS.

In this implementation, instead of doing any real work with powerful robots,  a mock manufacturing shop-floor scenario has been emulated that requires the robot only to travel among tasks. As discussed in Sec. \ref{expt-tools:btcom}, e-puck robots do not have on-board CPU, they need a host PC to  control them using BTCom communication protocol. Thus the host-PC  runs one RCC for each physical robot. These RCCs also rely upon SwisTrack multi-robot tracking system for updating their real-time pose. So although AFM based MRTA solution is distributed by design,  a centralized approach has been used to implement it due to the limitations of e-puck robots and the convenience of implementation. Below the actual implementations of these components is described, such as D-Bus communication interfaces and detail implementations of TPS and RCC.
%%---------------------------------------------------------------
\subsection{D-Bus communication interfaces}
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth, angle=0]
{./dia-files/RIL-Expt-Setup1.eps}
%figure caption is below the figure
\caption{Hardware and software setup for series A \& B experiments}
\label{fig:RIL-Expt-Setup1} % Give a unique label
\end{figure}
%%
A centralized communication system  interfaces among SwisTrack, TPS and RCC as shown in Fig. \ref{fig:RIL-Expt-Setup1}. The communication protocol is based on D-Bus IPC. As discussed in Sec. \ref{expt-tools:dbus}, each message is a D-Bus signal (similar to Fig. \ref{fig:dbus-signal-protocol}). The characteristics of these messages are discussed below.\\
%%
\textbf{\texttt{RobotPose}:} SwisTrack emits this D-Bus signal and its payload contains individual robot's pose data: robot-pose x-coordinate,  y-coordinate and robot orientation (theta). The type of each data is \texttt{DBUS\_TYPE\_DOUBLE} (IEEE 754 double). In this study SwisTrack  has been extended by adding a D-Bus signal emitter module which emits this signal in every image-processing cycle. The typical duration of each cycle varies from 1 to 2 seconds.  Swistrack extracts robot-pose from the image frame considering top-left corner of image as origin and it derives  theta from the relative position of the monochrome robot-marker from the image. SwisTrack's id-pose detection algorithms handles the complexities of finding the accurate robot-pose. \texttt{RobotPose} signal is sent to RCC using robot-id based separate D-Bus paths. e.g. \texttt{/robot1}, \texttt{/robot2} etc.  But all \texttt{RobotPose} signals are emitted in same D-Bus interface \texttt{uk.ac.newport.ril.SwisTrack}. In order to get pose data, each RCC filters this D-Bus signal using this interface and self-id based path.\\
%% 
\textbf{\texttt{TaskInfo}:} TPS emits this signal after a fixed time intervals. The payload of this message contains an array of all task's information. Each element of the array contains a task's: task-id, Time-stamp, pose x, pose y, task-urgency ($\phi$). Task-id data is integer type and  all others are double. Time-stamp in data ensures using up-to-date task information since RCCs receive \texttt{TaskInfo} from TPS asynchronously. If the tasks are dynamic their pose can be obtained from SwisTrack as well. In  this implementation,  static pose data have been provided to all task as an argument to TPS module. So the dynamic part, i.e. the time-stamp and up-to-date task-urgency is determined by the task-information-updater module of TPS, according to Algorithm 4.1. This D-Bus signal is sent in a common D-Bus interface, \texttt{uk.ac.newport.ril.TaskServer}, under path, \texttt{/taskserver}.  Each RCC receives this message by listening to this interface and path.\\
%%
\textbf{\texttt{RobotStatus:}} Each RCC emits this D-Bus signal and the payload contains: individual robot's id and its currently executing task's id. This message is sent to a common D-Bus interface \texttt{uk.ac.newport.ril.Epuck} and path \texttt{/robot}.  But TPS identifies the sender from the message pay-load, i.e. robot-id. A RCC emits this signal only when it starts working on a particular task. 
%------------------------------------------------------------
\subsection{Robot-controller client}
As shown in Fig. \ref{fig:RIL-Expt-Setup1}, each e-puck robot is controlled by a corresponding RCC. An RCC sends commands to the robot's firmware using BTCom protocol  (Sec. \ref{expt-tools:btcom}).
An RCC consists of several Python modules. Each module represents a sub-process under a main process that ties all of them together by using Python's Multiprocessing module. Below  the detail design and implementation of these Python modules  have been described. All code are publicly accessible through GitHub repository\footnote{git://@github.com/roboshepherd/EpuckCentralizedClient.git,    
\textit{hash:}7e3af8902e64db3fa59e}.
%%
\subsubsection*{\texttt{DataManager}}
As discussed in Sec. \ref{expt-tools:python}, under a process-based design of IPC among multiple processes, a programmer needs to specify explicitly which data and states should be shared among sub-processes. According to the design of the multi-robot control architecture, HEAD (Sec. \ref{expt-tools:arch}), a data and event management process called \texttt{DataManager}  have been employed that acts as a data warehouse and event management centre for RCC.\\
%%
\begin{table}
\caption{Data structures and events used by the RCC}
\begin{center}
\begin{tabular}{|l|l|}
\hline \textbf{Data structure} & \textbf{Related event(s)}\\ 
\hline \texttt{\texttt{mRobotID}} & - \\ 
\hline \texttt{mRobotPose} & \texttt{mRobotPoseAvailable}\\ 
\hline \texttt{mTaskInfo} & \texttt{mTaskInfoAvailable}\\ 
\hline \texttt{mSelectedTask} & \texttt{mSelectedTaskAvailable}\\
 &  \texttt{mSelectedTaskStarted}\\
 &  \texttt{mTaskTimedOut}\\
 \hline 
\end{tabular}
\end{center}
\label{table:data-mgr}
\end{table} 
%%
Table \ref{table:data-mgr} lists the major data structures and corresponding event channels of \texttt{Data Manager}. Here \texttt{mRobotID}, an integer type data,  represents the e-puck robot's marker ID (converted to decimal number from the binary code) which uniquely identifies a robot from others. This is given as a command-line argument during RCC start-up. Python {\em dictionary} type data structure  have been used  for all other data structures that are managed by the Python Multiprocessing's {\em Manager()} object. Any other process e.g. \texttt{TaskSelector}, can access \texttt{DataManager}'s data and event channels locally  by taking a reference of \texttt{DataManager} object from the Multiprocessing's parent process. \texttt{DataManager} object also runs a tiny TCP/IP server process powered by the Multiprocessing's {\em RemoteManager()} interface. So, if necessary,  any other process e.g. \texttt{DeviceController}, can access all of the DataManger's data structures and event channels remotely by instantiating a proxy client  that connects to this embedded TCP/IP server of \texttt{DataManager} and  fetch data from it. In the following paragraphs, under the discussion of other RCC processes, the update process of rest of the data structures and event channels are explained.
%%
\subsubsection*{\texttt{SignalListener}}
As mentioned in Sec. \ref{expt-tools:arch:integration}, two D-Bus communication modules in RCC:\\ \texttt{SignalListener} and \texttt{SignalEmitter} have been employed that are responsible for listening and emitting D-Bus signals respectively. \texttt{SignalListener}, has subscribed to D-Bus session bus for listening  to D-Bus \texttt{RobotPose} and \texttt{TaskInfo} signals that are discussed above. \texttt{SignalListener} uses two call-back functions that handles both of these signal reception events. For example when SwisTrack emits \texttt{RobotPose} signal  the corresponding handler function becomes activated and receive this \texttt{RobotPose} siganl's payload data (i.e. x, y , theta). It then makes a copy of these data  to \texttt{DataManager}'s \texttt{mRobotPose} data structure and label them as dictionary key/value pairs, where x, y, theta etc. becomes the dictionary keys. In addition to copying the data, \texttt{SignalListener} also set the \texttt{DataMager}'s   \texttt{mRobotPoseAvailable} event to {\em \texttt{True}}. In consequence, those processes that are waiting for \texttt{mRobotPose} data, e.g. \texttt{TaskSelector}, finishes their waiting and try to access this newly arrived \texttt{mRobotPose} data. After reading to this data they marks this \texttt{mRobotPoseAvailable} event as  {\em \texttt{False}} so that this pose data can be treated as outdated and waiting processes can wait for new pose update. This strategy ensures the consistent and real-time data read/write by all subscribing processes.
%%
\subsubsection*{\texttt{SignalEmitter}}
Similar to the \texttt{SignalListener}, \texttt{SignalEmitter} makes use of Python\\ {\em sched} module that enables it to check periodically \texttt{mSelectedTaskStarted} event and emit a robot's task status containing signal, \texttt{RobotStatus}.  This is done by subscribing to the  \texttt{mSelectedTaskStarted} event channel. When a robot executes a task, this event channel becomes  activated by\\ \texttt{DeviceController} (discussed below).\\ At a very close time, \texttt{SignalEmitter} gets this event update and finishes waiting for this event. It then picks up the \texttt{mSelectedTask} data from \texttt{DataManager} and prepare the \texttt{RobotStatus} signal and emits it to the session bus. Upon a successful emission event, it clears \texttt{ mSelected TaskStarted} event so that only one \texttt{RobotStatus}  signal is emitted per task-cycle.
%%
\subsubsection*{\texttt{TaskSelector}}
\texttt{TaskSelector} works in the application layer of multi-robot control architecture, HEAD. It plugs the AFM algorithms into RCC to select task based-on\\ \texttt{DataManger}'s event notifications , i.e. \texttt{mRobotPoseAvailable} and\\ \texttt{mTaskInfoAvailable} and upon running task-allocation algorithm it updates  \texttt{mSelectedTask} (and \texttt{mSelectedTaskAvailable}) with selected task information.

\texttt{TaskSelector}  allocates a robot with a shop-task or random-walk task from several inputs: as shown in Algorithm 4.1. Here  \textit{AllTaskInfo} and \textit{RobotPose} correspond to the \texttt{mTaskInfo} and \texttt{mRobotPose} of \texttt{DataManager}. \textit{TaskRecords} is a dictionary type data structure that keep tracks of related calculations, e.g. stimulus, of all tasks. This is internally maintained by the \texttt{TaskSelector} process.  \textit{DeltaDistance} is a very small constant number to avoid division by zero in calculating task stimuli, as mentioned in Eq. \ref{eqn:afm1}.\\
\textbf{Task-allocation algorithm:}\\
\textbf{Stage 1.} During the initialization of the task-allocation algorithm, the total number of tasks has been counted and initialize the sum of the stimuli all tasks to zero. Then for each task, its pose, urgency, sensitisation are extracted from input data.\\  \textit{CalculateTaskDistance()} function calculates the Euclidian distance between a task and a robot by taking the current robot-pose and static task-pose as the input. These values are enough to get a task's stimuli based on Eq. \ref{eqn:afm1}. In this loop finally  \textit{TaskRecords} is updated for using it in next task-allocation cycle. The random-walk task's stimuli is found from Eq. \ref{eqn:afm2}. It requires total number of shop-tasks and sum of their stimulus.
%% ALG
\newline
\textbf{Algorithm 4.1: Self-regulated task-allocation based on AFM}
\vspace{-3mm}
\newline
\HRule
\begin{algorithmic}[1]
\begin{small}
\label{alg:task-selector}
\State $\textbf{Input: } AllTaskInfo, RobotPose, TaskRecords, DeltaDistance$
\State $\textbf{Output: } SelectedTaskID$
\State \COMMENT {Stage 1: Get each task's individual stimuli and sum  all stimulus}
\State $TotalTasks \gets$  Total number of tasks $\in AllTaskInfo$  
\State $ TaskStimuliSum \gets 0 $
\ForAll {$ Task \in AllTaskInfo $} 
\State $ TaskPose \gets  $ Task-position  $ \in Task$
\State $ TaskUrgency \gets $ Task-urgency $ \in Task$
\State $ TaskSensitization \gets $ Task-sensitization $\in Task$
\State $ DistanceToTask \gets  $\textbf{CalculateTaskDistance(}$RobotPose$, $TaskPose$\textbf{)}
\State $ TaskStimuli \gets  $ \textbf{CalculateTaskStimuli(}$DistanceToTask,$\\ \hspace*{3.5cm} $TaskSensitization, 	        TaskUrgency, DeltaDistance\textbf{)}$
\State $ TaskStimuliSum \gets$  $TaskStimuliSum + TaskStimuli$
\State $ TaskRecords \gets $ \textbf{UpdateTaskRecords(}$TaskStimuli,$\\ \hspace*{3.5cm}$DistanceToTask, TaskUrgency, TaskSensitization\textbf{)}$
\EndFor
%%
\State $RandomWalkStimuli \gets $ \textbf{CalculateRandomWalkStimuli(}$TotalTasks,$\\ \hspace*{4.5cm} $TaskStimuliSum$\textbf{)}
\State $ AllStimuliSum \gets TaskStimuliSum + RandomWalkStimuli $
%%
\State \COMMENT {Stage 2: Find probability of each task based on its stimuli}
\State $ TaskID \gets 0 $ 
\While {$ TaskID \leq TotalTasks $} 
\State $ TaskStimuli \gets $ Task-stimuli $\in TaskRecords(TaskID)$
\State $ TaskProbability \gets  $ \textbf{GetTaskProbability(}$TaskStimuli, AllStimuliSum$\textbf{)}
\State $ TaskProbabilityRange \gets $ \textbf{ConvertTaskProbabilityIntoRange(}\\ \hspace*{6cm}$TaskProbability$\textbf{)}
\State $ TaskRecords \gets  $ \textbf{UpdateTaskRecords(}$TaskProbability$\textbf{)}
\EndWhile
%%
\State \COMMENT {Stage 3: Draw a random-number to match with TaskID}
\State $ RandomNum \gets  $ \textbf{GetRandomNumber(}$0,$ \textbf{Max(}$TaskProbabilityRange$\textbf{))}
\While {$ TaskID \leq TotalTasks $} 
\State $ RangeStart \gets  $ \textbf{Min(}$TaskProbabilityRange (TaskID)$\textbf{)}
\State $ RangeEnd \gets  $ \textbf{Max(}$TaskProbabilityRange (TaskID)$\textbf{)}
\If {$  RandomNum \geq RangeStart \hspace*{.25cm}\&\& \hspace*{.25cm} RandomNum \leq  RangeEnd $}
\State $ SelectedTaskID \gets TaskID $ 
\EndIf
\EndWhile
\end{small}
\end{algorithmic}
\vspace{-3mm} 
\HRule\\
%%
\textbf{Stage 2.} In the second stage of this task-allocation algorithm, the probability of each task (including random-walk) can be found based on Eq. \ref{eqn:afm3}. Then this probability value of each task, between 0 and 1, is rounded to the closest two-digit fractions and multiplied by 100 and put into a linear scale. For example, if two tasks probability values are: 0.15 and  0.25, the probability range of first  task becomes 0 to 15 and for second task, it becomes 16 to 40.\\
%% 
\textbf{Stage 3.} After converting each task's probability values into a linear range,  a random-number generator is used that draws a random-number between 0 and the highest value of task-probability range, say 40 for the previous example. Then this random number is compared against the task probability range of each task. For the above example, if the random-number becomes 37, the task-probability range checking function selects \textit{Task2} since 37 falls between 16 to 40. Under this probabilistic method, the task with larger probability range has a  higher chance to be selected, but low probability tasks are also got selected time-to-time.
%%
\begin{sidewaysfigure}
\centering
\includegraphics[width=18cm,height=11cm]
{./dia-files/rcc-device-controller-state.eps}
%figure caption is below the figure
\caption{State diagram of \texttt{DeviceController} module}
\label{fig:dc-states} % Give a unique label
\end{sidewaysfigure}
%%
\newline
\textbf{Algorithm 4.2: Robot's learning and forgetting of tasks based on AFM}
\vspace{-3mm}
\newline
\HRule
\begin{algorithmic}[1]
\begin{small}
\label{alg:update-sz}
\State $\textbf{Input: }  TaskRecords, LeranRate, ForgetRate, SelectedTaskID$
\State $\textbf{Output: }$ Updated $TaskSensitisation \in TaskRecords$
\ForAll {$ Task \in TaskRecords $} 
\State $ TaskID \gets  $ ID $\in Task$
\State $ TaskSensitization \gets  $   Sensitisation $ \in Task$
\If {$  TaskID \equiv SelectedTaskID $}
\State $ TaskSensitization \gets $ \textbf{Max(}$1, (TaskSensitization + LeanRate)$\textbf{)}
\Else
\State $ TaskSensitization \gets $ \textbf{Min(}$0, (TaskSensitization - ForgetRate)$\textbf{)}
\EndIf
\EndFor
\end{small}
\end{algorithmic}
\vspace{-3mm} 
\HRule\\
%%
\textbf{Robot learning and forgetting algorithm:}\\
Algorithm 4.2 lists the pseudo-code for updating the robot's task-sensitization values. Along with previously mentioned \textit{TaskRecords}, and  \textit{SelectedTaskID}, it takes two other inputs: \textit{LeranRate} ($\Delta k_{INC} $) and \textit{ForgetRate} ($\Delta k_{INC} $) as outlined in Eq. \ref{eqn:k-inc} and \ref{eqn:k-dec} respectively.  In addition to that it also keep the value of task-sensitization between the fixed limit of 0 and 1.
%%
\subsubsection*{\texttt{DeviceController}:}
\label{afm:impl:dc}
The final code that moves a robot to desired task location or make random-walk resides in \texttt{DeviceController} module. This is also a separate sub-process of Python Multiprocessing based mother process. It waits for the \texttt{DataManager}'s \texttt{mRobotPoseAvailable} and \texttt{mSelectedTaskAvailable} events. When \texttt{TaskSelector} sets  \texttt{mSelectedTaskAvailable} event,\\ \texttt{DeviceController} sub-process checks the Bluetooth link-connectivity with physical robot. In case of successful task start-up it sets\\ \texttt{mSelectedTaskStarted} event that, in turn, triggers \texttt{SignalEmitter} to emit a D-Bus signal publishing the robot's currently engaged task. The full state switching policies of\\ \texttt{DeviceController} is illustrated in Fig. \ref{fig:dc-states}. Externally one can observe two distinct physical state of a robot: it is either idle or in motion (separated by dotted line). These two physical states are mapped into several logical steps:\\
%%
\textbf{DeviceUnavailable: }
Initially, \texttt{DeviceController} sets it state as \textit{DeviceUnavailable} (e.g. not connected with Bluetooth link) and after a fixed short-time intervals it checks whether the device has connected to host-PC, i.e. after the  wireless link becomes up. In that case, \texttt{DeviceController} switches its state to \textit{DeviceAvailable} (i.e device connected). One can see that from every other state, device can come to this unavailable state (shown by dotted arrow) when the  link is lost e.g. in case of robot's low battery or any other disconnection event (i.e device disconnected).\\
%%
\textbf{DeviceAvailable: }
\texttt{DeviceController} stays in this state until\\ \texttt{Data-Manager}'s mSelectedTaskAvailable event fires ({\em Device connected, no task selected}). Then it switches to either \textit{MoveToTask} or \textit{RandomWalk} state depending on the selected task.  \texttt{DeviceController}  returns to this state from \textit{RandomWalk}, \textit{MoveToTask} or \textit{AtTask} states after a pre-set task time-out period has elapsed.  In that case it triggers the \texttt{DataManager}'s \texttt{mTaskTimedOut} event.\\
%%
\textbf{RandomWalk: }
Robot can random walk in two cases: 1) when \texttt{TaskSelector} selects this random-walk task or 2) when the robot can not get its pose information for a moment. The latter helps the pose tracker to recover the robot-pose from a crowd of robots. Robot continues to do random-walk until its task time-out period elapses or its pose remains unavailable from the pose tracker (i.e. random-walk pending).\\
%%
\textbf{MoveToTask: }
In this state, robot takes step-by-step navigation approach to reach a task boundary. Until the robot reaches the task boundary ({\em Away from task}), in every navigation-step it adjusts its heading to task based on both  robot and task pose information and then makes a fixed-time translation movement. In worse cases, when time-out happens early before reaching a task  \texttt{DeviceController}\\ switches from this state to\textit{ DeviceAvailable} state. However, if the same task is selected immediately, it is more likely that it will go to \textit{AtTask} state in next step.
%%
\textbf{AtTask: }
In this state  \texttt{DeviceController} discovers itself neat the task and normally until task time-out happens (i.e. task pending) it stays at this state.
%-------------------------------------------------------------------
\subsection{Task-perception server}
%%
Similar to RCC,  TPS has two D-Bus communication components\\ \texttt{SignalListener} and \texttt{SignalEmitter}, and a data and event management component \texttt{DataManager} (Fig. \ref{fig:concrete-arch}).\\ 
\textbf{Algorithm 4.3: Task-urgency update rules  based on AFM}
\vspace{-3mm}
\newline
\HRule
%% ALG
\begin{algorithmic}[1]
\begin{small}
\label{alg:tps}
\State $\textbf{Input: } AllTaskInfo, AllTaskWorkers, ThresholdWorkers,$\\ \hspace*{1cm}$DeltaUrgencyINC, DeltaUrgencyDEC$
\State $\textbf{Output: }$ Updated $TaskUrgencies \in AllTaskInfo$
\ForAll {$ (Task, Workers) \in (AllTaskInfo, AllTaskWorkers) $} 
\State $ TaskUrgency \gets  $ Task-urgency $\in Task$
\State $ TaskWorkers \gets  $   Number of workers $ \in Workers$
\If {$  TaskWorkers < ThresholdWorkers $}
\State $ TaskUrgency \gets $ \textbf{Max(}$1, (TaskUgerncy + DeltaUrgencyINC)$\textbf{)}
\Else
\State $ TaskUrgency \gets $ \textbf{Min(}$0, (TaskUgerncy - $\\ \hspace*{5.3cm}$ TaskWorkers  \times DeltaUrgencyDEC)$\textbf{)}
\EndIf
\EndFor
\end{small}
\end{algorithmic}
%%
\vspace{-3mm} 
\HRule\\
This instance of \texttt{DataManager} stores statistics about task performance of robots in a dictionary a type data structure (\texttt{mTaskWorkers}). This data structure is\\ updated every time a \texttt{RobotStatus} signal is received from a RCC. It is a dictionary type data structure where ID of tasks are keys and ID of robots are the values of this dictionary. Based on this data structure, an application layer component, \texttt{TaskInfoUpdater}, updates the task-urgencies after every short time intervals. This update algorithm in presented in Algorithm 4.3.  Along with the static task-pose information, all task-urgencies are stored in the \texttt{mTaskInfo} data structure of  \texttt{DataManager} of TPS. This TPS's \texttt{SignalEmitter} waits for the update of \texttt{mTaskInfo} and after every certain intervals it emits this up-to-date \texttt{TaskInfo} signal.

This algorithm acts upon the task-urgency data of each task and updates it based on the active number of robots currently working on that task (Eq. \ref{eqn:delta-phi1} and \ref{eqn:delta-phi2}). Here \textit{AllTaskInfo} and \textit{AllTaskWorkers}  correspond to  \texttt{mTaskInfo} and\\ \texttt{mTaskWorkers} of TPS \texttt{DataManager} respectively.  \textit{ThresholdWorkers} are the minimum number of robots required to work on this task ($\mu$). \textit{DeltaTaskUrgencyINC} and\\ \textit{DeltaTaskUrgencyDEC} are the task-urgency increase and decrease rate which correspond to the small increase and decrease of work-load in every-step. This algorithm also keeps the values of task-urgencies within 0 and 1 limit by using generic \textit{Min( )} and \textit{Max( )} functions. Source-code of a Python implementation of TPS is publicly accessible through GitHub repository\footnote{git://github.com/roboshepherd/CentralizedTaskServer.git,  \textit{hash:} 09187e28292d1cdc179c}.
%%====================================================================
\section{Results}
\label{afm:results}
In this section experimental results  have been presented. Those experiments were up and running for about 40 minutes and average was taken from five iterations for both Series A and B. 
%%-------------------------------------------------
\subsection*{Shop-floor work-load history}
In these experiments, shop-floor work-load is defined  in terms of task urgencies. For example, Eq. \ref{eqn:task-urgency-prod-init} shows how initial production work-load of the manufacturing shop-floor scenario can be calculated.
%%
\begin{figure}[H]
%\begin{minipage}[t]{0.48\linewidth}
\centering
\includegraphics[height=8cm, angle=0]
{images/global-8robots/PlotUrgencyLog-2010Apr30-095755.eps}
%figure caption is below the figure
\caption{\small Changes in task-urgencies in Series A experiments}
\label{fig:raw-urgencies-SA} 
%\end{minipage}
%\hspace{0.5cm}
%\begin{minipage}[t]{0.48\linewidth}
\centering
\includegraphics[height=8cm, angle=0]{images/PlotUrgencyLog-2010May10-115549.eps}
\caption{\small Changes in task-urgencies in Series B experiments} 
\label{fig:raw-urgencies-SB} 
%\end{minipage}
\end{figure}

Fig. \ref{fig:raw-urgencies-SA} and Fig. \ref{fig:raw-urgencies-SB}  show the dynamic changes in task-urgencies for the single iteration of Series A and Series B experiments respectively. The fluctuations in these plots are resulted from the different levels of task-performance of e-puck robots.

In order to measure the task-related work-loads on the system   the changes in all task-urgencies are summed up over time.  This is called as {\em shop-floor work-load history} and formalized as follows. Let $ \phi_{j, q}$ be the urgency of a task $j$ at $q^{th}$ step and $\phi_{j, q+1}$ be the task urgency of $(q+1)^{th}$ step. The sum of changes in urgencies of all $M$ tasks  can be calculated at $(q+1)^{th}$ step:
\begin{equation} 
\Delta \Phi_{j, q+1} = \sum_{j=1}^{M} (\phi_{j, q+1} - \phi_{j, q})
\label{eqn:Delta-Phi}
\end{equation}
%%
\begin{figure}[H]
%\begin{minipage}[t]{0.48\linewidth}
\centering
\includegraphics[height=8cm, angle=0]
{images/global-8robots/8robots2tasks-TaskUrgencyStat.eps}
%figure caption is below the figure
\caption{\small Shop-floor workload change history in Series A} 
\label{fig:urgency-stat-SA} % Give a unique label
%\end{minipage}
%\hspace{0.5cm}
%\begin{minipage}[t]{0.48\linewidth}
\centering
\includegraphics[height=8cm, angle=0]{images/TaskUrgencyStat.eps}
\caption{\small Shop-floor workload change history in Series B} % measured in terms of task urgencies
\label{fig:urgency-stat-SB} % Give a unique label
%\end{minipage}
\end{figure}
%%
Fig. \ref{fig:urgency-stat-SA} and Fig. \ref{fig:urgency-stat-SB} show the dynamic shop-floor workload for Series A and Series B experiments respectively. From these plots, it can be seen that initially the sum of changes of task urgencies (shop-floor workload) is going towards negative direction. This implies that tasks are being served by a high number of robots.
%%----------------------------------------------------------------
\subsection*{Ratio of active workers}
%%
\begin{figure}[H]
%\begin{minipage}[t]{0.48\linewidth}
\centering
\includegraphics[height=8cm, angle=0]
{images/global-8robots/Plasticity-8robots2tasks.eps}
%figure caption is below the figure
\caption{\small Self-organized allocation of robots in Series A}
\label{fig:worker-stat-SA}
%\end{minipage}
%
%\hspace{0.5cm}
%\begin{minipage}[t]{0.48\linewidth}
\centering
\includegraphics[height=8cm, angle=0]{images/WorkerRatio.eps}
\caption{\small Self-organized allocation of robots in Series B }
\label{fig:worker-stat-SB} % Give a unique label
%\end{minipage}
\end{figure}
%%
From both Fig. \ref{fig:worker-stat-SA} and Fig. \ref{fig:worker-stat-SB}, one can  see that in production stage, when work-load is high, many robots are active in tasks. Here active workers ratio is the ratio of those robots that work on tasks to the total number of robots $N$ of a particular experiment.   Here one can see that this ratio varies according to the shop-floor work-load changes.
%%-------------------------------------------------------------
\subsection*{Shop-task performance}
In the manufacturing shop-floor scenario, the APCD and APMW for both Series A and Series B experiments have been calculated. For Series A, the average production completion time is found at 111 time-step (555s) where sample size is (5 x 2) = 10 tasks, SD = 10 time-steps (50s). According to Eq. \ref{eqn:min-pmm}, the theoretical minimum production completion time is 50 time-steps (250s) assuming the non-stop task performance of all 8 robots with an initial task urgency of 0.5 for all 2 tasks and task urgency decrease rate $\Delta \Phi_{DEC }$ = 0.0025 per robot per time-step.  Hence, Eq. \ref{eqn:appd} gives APCD, $\zeta$ = 1.22 which means that in Series A experiments, it took 1.22 times more time (305s) than the estimated minimum production completion time (250s). For Series B, average production completion time is 165 time-steps (825s) where sample size is (5 x 4) = 20 tasks, SD = 72 time-steps (360s).  Hence, Eq. \ref{eqn:appd} gives APCD, $\zeta$ = 2.3.
%% 
\begin{figure}[H]
%\begin{minipage}[t]{0.48\linewidth}
\centering
\includegraphics[height=7cm, angle=0]{images/apcd-SA-SB.eps}
\caption{APCD of Series A and Series B experiments.}
\label{fig:apcd-SA-SB} 
%\end{minipage} 
%%%
%\hspace{0.5cm}
%\begin{minipage}[t]{0.48\linewidth}
\centering
\includegraphics[height=7cm, angle=0]
{images/apmw-SA-SB.eps}
\caption{APMW of Series A and Series B experiments.}
\label{fig:apmw-SA-SB} % Give a unique label
%\end{minipage}
\end{figure}
%%
Fig. \ref{fig:apcd-SA-SB} shows the APCD for both Series A and Series B experiments. \\
%%
For APMW, Series A experiments give an average time length of 369 time-steps (1845s).  In this period APMW is calculated and it corresponds to 1 time-step with SD = 1 time-step (5s) and $\Delta \Phi_{INC}$ = 0.005 per task per time-step. This shows a very low APMW ($\chi$ = 0.000235) and a very high robustness of the system. For Series B experiments, from the average 315 time-steps (1575s) maintenance activity of robots per experiment run,  APMW has become $\chi$ = 0.012756 which corresponds to the pending work of 3 time-steps (15s) where SD = 13 time-steps (65s). This tells the robust task performance of e-puck robots which can return to an abandoned task within a minute or so. Fig. \ref{fig:apmw-SA-SB} plots the APMW for both Series A and Series B experiments. 
%%-------------------------------------------------
\subsection*{Task specializations}
The task-specialization of the robots have been measured based-on their peak value of sensitization. This maximum value represents how long a robot has repeatedly been selecting a particular task. Since tasks are homogeneous  the maximum sensitization value of a robot among all tasks is considered during an entire experiment run. This value is then averaged for all robots using the following  equation. 
%%
\begin{equation}
K^G_{avg} = \frac{1}{N}\sum_{i=1}^{N} \max_{j=1}^M\left ( k^i_{j, q} \right ) 
\label{eqn:K-G}
\end{equation}
%%
If a robot $r_i$ has the peak sensitization value $k^i_j$ on task $j$ ($j \in M$ tasks)  at $q^{th}$ time-step, Eq. \ref{eqn:K-G} calculates the average of the peak task-specialization values of all robots for a certain iteration of the experiments.  The time-step values ($q$)  have been averaged to reach those peak values for all robots using the following equation.
%%
\begin{equation}
Q^G_{avg}= \frac{1}{N}\sum_{i=1}^{N} q^i_{k=k_{max}}
\label{eqn:Q-G}
\end{equation}
In Eq. \ref{eqn:Q-G}, $q^i_{k=k_{max}}$ represents the time-step of robot $r_i$  where its sensitization value $k$ reaches the peak $k_{max}$ as discussed above. By averaging this peak time-step values of all robots one can have an overall idea of how many task-execution cycles are spent to reach the maximum task-specialization value $K^G_{avg}$.
%% S-A
\begin{table}[H]
\centering
\caption{Peak task-sensitization values of robots in a Series A experiment.}
% 30Apr expt.
\begin{tabular}{|c|c|c|c|}
\hline \textbf{Robot ID} & \textbf{Maximum k} & \textbf{At time-step (q)} & \textbf{Task} \\ 
\hline 1 & 0.54 & 64 & Task1\\
\hline 4 & 0.32 & 14 & ,,\\
\hline 5 & 0.27 & 11 & ,,\\
%%
\hline 3 & 0.47 & 63 & Task2\\
\hline 2 & 0.46 & 64 & ,,\\
\hline 6 & 0.20 & 10 & ,,\\
\hline 7 & 0.18 & 4 & ,,\\
\hline 8 & 0.15 & 3 & ,,\\
\hline 
\end{tabular} 
\label{table:K-G-SA}
\end{table}
%% S - B
\begin{table}[H]
\centering
\caption{Peak task-sensitization values of robots in a Series B experiment.}
\begin{tabular}{|c|c|c|c|}
% Apr 18 Feb-3 expt
\hline \textbf{Robot ID} & \textbf{Maximum k} & \textbf{At time-step (q)} & \textbf{Task} \\
\hline 24 & 0.41 & 29 & Task1\\
\hline 13 & 0.31 & 19 & ,,\\
\hline 16 & 0.18 & 4 & ,,\\
%% 
\hline 1 & 0.64 & 66 & Task2\\
\hline 35 & 0.34 & 12 & ,,\\
\hline 5 & 0.28 & 14 & ,,\\
\hline 22 & 0.18 & 20 & ,,\\
\hline 17 & 0.16 & 6 & ,,\\
\hline 3 & 0.14 & 12 & ,,\\
%%
\hline 9 & 0.68 & 66 & Task3\\
\hline 6 & 0.43 & 71 & ,,\\
\hline 15 & 0.19 & 4 & ,,\\
\hline 14 & 0.15 & 4 & ,,\\
\hline 31 & 0.14 & 4 & ,,\\
%%
\hline 19 & 0.22 & 12 & Task4\\
\hline 12 & 0.16 & 10 & ,,\\
\hline 
\end{tabular} 
\label{table:K-G-SB}
\end{table}
Table \ref{table:K-G-SA} and Table \ref{table:K-G-SB} show sample peak sensitization values of Series A and Series B experiments respectively.  Based on Eq. \ref{eqn:K-G} and Eq. \ref{eqn:Q-G},  the peak task-sensitization $K^G_{avg}$ values are found as 0.40 (SD=0.08)  and 0.30 (SD=0.03), and their respective time-step $Q^G_{avg}$ values: 38 (SD=13) and 18 (SD=5) time-step. 
%%
\begin{figure}[H]
%\begin{minipage}[t]{0.48\linewidth}
\centering
\includegraphics[height=7cm, angle=0]{images/K-G-SA-SB.eps}
\caption{ Overall task-specialization of robot groups.}
\label{fig:K-G-SA-SB} 
%\end{minipage} 
%%%
%\hspace{0.5cm}
%\begin{minipage}[t]{0.48\linewidth}
\centering
\includegraphics[height=7cm, angle=0]
{images/Q-G-SA-SB.eps}
\caption{Time-steps to reach the peak values of task-specialization}
\label{fig:Q-G-SA-SB} 
%\end{minipage}
\end{figure}

They are shown in Fig. \ref{fig:K-G-SA-SB} and Fig. \ref{fig:Q-G-SA-SB}. Here one can see that the robots in Series A have higher chances of task-specialization than that of Series B experiments.

%% ------ Single robot----
\begin{figure}[H]
\centering
\includegraphics[width=\textwidth, angle=0]{images/TaskSpecialization-task3-10may-1.eps}
\caption{Task specialization on Task3 for a Series B experiment.}
\label{fig:k-single-task-SB} 
\end{figure}
%%
Fig. \ref{fig:k-single-task-SB} shows the task specialization of five robots on Task3 in a particular run of Series B experiment. This shows how some of the robots can specialize (learn) and de-specialize (forget) tasks over time.
%%-------------------------------------------------
\subsection*{Robot motions}
The changes in translation motion of all robots  have been aggregated over time. Let $u_{i,q}$ and $u_{i,q+1}$ be the translations of a robot $i$ in two consecutive steps. If the difference between these two translations be $\delta u_{i}$, one can find the sum of changes of translations of all robots in $(q+1)^{th}$ step using the following equation.
\begin{equation}
\Delta U_{q+1} = \sum_{i=1}^{N} \delta u_{i, q+1} 
\label{eqn:Delta-Tr}
\end{equation}
%%%%
\begin{figure}[H]
%\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[height=7cm]{images/global-8robots/8robots-DeltaTranslationStat.eps}
\caption{\small Sum of the translations of robots in Series A experiments}
\label{fig:translation-stat-SA} % Give a unique label
%\end{minipage}
%\hspace{0.5cm}
%\begin{minipage}[t]{0.5\linewidth}
\end{figure}
%%
\begin{figure}[H]
\centering
\includegraphics[height=7cm]{images/global/DeltaTranslationStat.eps}
\caption{\small Sum of the translations of robots in Series B experiments}
\label{fig:translation-stat-SB} % Give a unique label
%\end{minipage}
\end{figure}
The results from Series A and Series B experiments are plotted in Fig. \ref{fig:translation-stat-SA} and Fig. \ref{fig:translation-stat-SB}. In this plot one can see that robot translations also vary over varying task requirements of tasks.
%%%-------------------------------------------------
\subsection*{Communication load}
%%% Communication load %%%
\begin{figure}[H]
%\begin{minipage}[t]{0.5\linewidth}
\centering
\includegraphics[height=7cm]
{images/global-8robots/8Robot-SignalingFreqStat.eps}
\caption{\small Frequency of \texttt{TaskInfo} signalling in Series A experiments}
\label{fig:signal-frequency-stat-SA} 
%\end{minipage}
%\hspace{0.5cm}
%\begin{minipage}[t]{0.5\linewidth}
\end{figure}
%%
\begin{figure}[H]
\centering
\includegraphics[height=7cm]{images/Global-SignalingFreqStat.eps}
\caption{\small Frequency of \texttt{TaskInfo} signalling in Series B experiments}
\label{fig:signal-frequency-stat-SB} 
%\end{minipage}
\end{figure}
%%
Fig. \ref{fig:signal-frequency-stat-SA}  and Fig. \ref{fig:signal-frequency-stat-SB}  show the number of received \texttt{TaskInfo} signals by each robot in Series A and Series B experiments. Since the duration of each time-step is 50s long and TPS emits signal in every 2.5s, there is an average of 20 signals in each time-step.
%===================================================================
\section{Discussions}
\label{afm:discuss}
%%-------------------------------------------------
\textbf{Self-regulated DOL}. From the experimental results, several aspects of self regulated DOL have been noted that exposes the power of AFM. As it is pointed out that this self-regulated DOL, as observed in biological and human social systems, needs to satisfy several important characteristics, e.g. plasticity, task-specialization. In addition to satisfying those basic qualities, AFM has demonstrated many other aspects. These self-regulated e-puck robots, driven by AFM, effectively handle the dynamic work-load of a manufacturing shop-floor. They can dynamically support the need to work on currently demanding tasks, if there any. The variations of active worker ratio supports this. 

From the self-organized worker allocations of AFM, it is clear that although in larger system (Series B) the degree of variations of active-worker ratio can show significantly unpredictable patterns, nevertheless the self-regulated rules drive the robots to respond to the dynamic needs of the system. This means that AFM can sufficiently produce the plasticity of DOL in order to meet the dynamic work-load of the system.

\textbf{Learning and Forgetting}. From the individual and group-level task specialization, one can see that robots can maintain both task-specialization and flexibility. In a self-organized system, it is very common that only a few individuals specialize on tasks and others generally do not. From two samples data sets, one can see that in particular runs of Series A and Series B experiments, task-sensitization values of  only 2-3 robots reach above the group-level average score. Thus in both types of experiments, robots exhibit similar task-specialization behaviours. 

From task-sensitization one can also see that a limited number of robots are specialized in tasks. Thus most of the other robots are flexible in selecting any tasks as their task-specializations do not bind them to particular tasks.

\textbf{Concurrency and robustness}. As a consequence of fewer robots specializing in tasks, one can also see that robots can concurrently  consider different tasks without being biased to a particular task all the time. These experiments also show the robust DOL as in case of  both high and low work-loads present in the system. This is evident from the manufacturing shop-floor task performance during PMM and MOM. For example,  in case of Series B experiments APMW was 13 time-steps (65s) which corresponded  to pending work-load of 0.065 unit for a single robot. Thus, on an average, before the work-load exceeded by about 13 percent of initial work-load, robots were able to respond to  a task.

\textbf{Communication load.} In these experiments  a centralized communication system (source of attractive fields) is used that serves the robots with necessary task-perception information. Although the robot-controllers software RCC was also co-located in the same host-PC, they can be distributed to several PCs or robot's on-board PCs. The centralized communication system has the advantage of minimising the communication load and the disadvantage of a single point of failure as well as a single point of load. In the next chapter the decentralized task perception is presented which uses P2P communications among RCCs.

\textbf{Scaling-up}. The system size of Series B is double than that of Series A in terms of robots, tasks and experiment arena.  A fixed ratio of robot-to-task and task-to-arena has been kept in order to see the scaling effects in different experiments. Here both systems have showed sufficient self-regulated DOL, but task-performance in both systems has varied significantly. For example, the value of APCD in Series B is higher by 1.08. This means that performance  is decreased in Series B experiments despite having the resources in same proportion in both systems. This occurs partly due to the greater stochastic effects found in task-allocation in a larger system, e.g. presence of more tasks produce higher stochastic behaviours in robot's task selection.

Similarly it is seen that in a larger system robots have less chances to specialize on tasks, as the Series B experiments show  that the overall average task-specialization of the group $K^G_{avg}$ is lower by 0.10 and it lasts for significantly less time (the difference of $Q^G_{avg}$  of both systems is 20 time-steps). Thus, in a large group, robots are more likely to switch among tasks more frequently and this produces more translation motions which cost more energy (e.g. battery power) in task-performance.

\textbf{Selection of limited number of trials/experiments}. The justification for choosing five trials of experiments goes as follows.  Real-robotic experiments face the actual challenge of real-world implementation unlike software simulation. Thus, what can not be discovered in hundreds of simulation runs, can naturally appear in a single or a few runs of a real-robotic experiments. Thus a set of five trials have been chosen that represent a realistic target for a single-man implementation of a fairly large multi-robot system. This choice is made after an insightful literature survey on the existing real-robotic systems. This decision has been influenced by some recent studies on swarm robotic systems, such as \citeasnoun{Pugh+2009}, \citeasnoun{Rutishauser+2009} and \citeasnoun{Agassounon+2004}. 
\vspace*{1cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Summary}
\label{afm:summary}
In this chapter,  The effectiveness of an inter-disciplinary generic model of self-regulated DOL, AFM, have been validated in order to address MRTA problem. AFM have been incorporated  in a multi-robot system with 8 and 16 robots under a manufacturing shop-floor scenario. A centralized communication system has been instantiated to realize this model.  Various aspects of this model have been evaluated, such as ability to meet dynamic task demands, individual task specializations, communication loads and flexibility in concurrent task completions. A set of metrics has been formalized to observe the self-regulated DOL in this system. From the experimental results,  it is confirmed that AFM can meet the requirements of dynamic MRTA by the virtue of its self-regulatory principles.